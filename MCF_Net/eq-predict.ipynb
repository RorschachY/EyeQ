{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_path = '10'\n",
    "proc_path = '10processed'\n",
    "quality = 'left10p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "from progress.bar import Bar\n",
    "import torchvision.transforms as transforms\n",
    "from dataloader.EyeQ_loader import DatasetGenerator\n",
    "from utils.trainer import train_step, validation_step, save_output\n",
    "from utils.metric import compute_metric\n",
    "\n",
    "import pandas as pd\n",
    "from networks.densenet_mcf import dense121_mcs\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Setting parameters manually for notebook environment\n",
    "parser = argparse.ArgumentParser(description='EyeQ_dense121')\n",
    "parser.add_argument('--model_dir', type=str, default='./result/')\n",
    "parser.add_argument('--pre_model', type=str, default='DenseNet121_v3_v1')\n",
    "parser.add_argument('--save_model', type=str, default='DenseNet121_v3_v1')\n",
    "parser.add_argument('--crop_size', type=int, default=224)\n",
    "parser.add_argument('--label_idx', type=list, default=['Good', 'Usable', 'Reject'])\n",
    "parser.add_argument('--n_classes', type=int, default=3)\n",
    "parser.add_argument('--epochs', default=20, type=int)\n",
    "parser.add_argument('--batch-size', default=4, type=int)\n",
    "parser.add_argument('--lr', default=0.01, type=float)\n",
    "parser.add_argument('--loss_w', default=[0.1, 0.1, 0.1, 0.1, 0.6], type=list)\n",
    "\n",
    "# Simulating command line arguments\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "import fundus_prep as prep\n",
    "import glob\n",
    "import os\n",
    "import cv2 as cv\n",
    "from PIL import ImageFile\n",
    "from tqdm import tqdm\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import h5py\n",
    "\n",
    "def process(image_list, save_path):\n",
    "    \n",
    "    for image_path in tqdm(image_list):\n",
    "        dst_image = os.path.splitext(image_path.split('/')[-1])[0]+'.png'\n",
    "        dst_path = os.path.join(save_path, dst_image)\n",
    "        if os.path.exists(dst_path):\n",
    "            print('continue...')\n",
    "            continue\n",
    "        try:\n",
    "            img = prep.imread(image_path)\n",
    "            r_img, borders, mask = prep.process_without_gb(img)\n",
    "            r_img = cv.resize(r_img, (800, 800))\n",
    "            prep.imwrite(dst_path, r_img)\n",
    "            # mask = cv.resize(mask, (800, 800))\n",
    "            # prep.imwrite(os.path.join('./original_mask', dst_image), mask)\n",
    "        except:\n",
    "            print(image_path)\n",
    "            continue\n",
    "\n",
    "list_left10 = glob.glob('/opt/notebooks/{}/*_0_0.png'.format(orig_path)) + glob.glob('/opt/notebooks/{}/*_0_1.png'.format(orig_path))\n",
    "save_left10 = prep.fold_dir('/opt/notebooks/{}'.format(proc_path))\n",
    "process(list_left10, save_left10)\n",
    "\n",
    "model = dense121_mcs(n_class=args.n_classes)\n",
    "\n",
    "if args.pre_model is not None:\n",
    "    loaded_model = torch.load('/opt/notebooks/DenseNet121_v3_v1.tar',map_location=torch.device('cpu') )\n",
    "    model.load_state_dict(loaded_model['state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "# glob G:\\ukb\\fundus_nomh_processed png file \n",
    "import glob\n",
    "label = glob.glob('/opt/notebooks/{}/*.png'.format(proc_path))\n",
    "label = [os.path.basename(x) for x in label]\n",
    "label = pd.DataFrame(label, columns=['image'])\n",
    "label['quality'] = 0\n",
    "label['DR_grade'] = 0\n",
    "# to csv with index\n",
    "label.to_csv('/opt/notebooks/{}.csv'.format(proc_path), index=True)\n",
    "# Images Labels\n",
    "test_images_dir = \"/opt/notebooks/{}/\".format(proc_path)\n",
    "label_test_file = \"/opt/notebooks/{}.csv\".format(proc_path)\n",
    "\n",
    "# options\n",
    "cudnn.benchmark = True\n",
    "\n",
    "transformList2 = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "transform_list_val1 = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "    ])\n",
    "\n",
    "data_test = DatasetGenerator(data_dir=test_images_dir, list_file=label_test_file, transform1=transform_list_val1,\n",
    "                             transform2=transformList2, n_class=args.n_classes, set_name='test')\n",
    "test_loader = torch.utils.data.DataLoader(dataset=data_test, batch_size=args.batch_size,\n",
    "                                          shuffle=False, num_workers=0, pin_memory=True)\n",
    "outPRED_mcs = torch.FloatTensor()\n",
    "\n",
    "model.eval()\n",
    "iters_per_epoch = len(test_loader)\n",
    "bar = Bar('Processing {}'.format('inference'), max=len(test_loader))\n",
    "bar.check_tty = False\n",
    "for epochID, (imagesA, imagesB, imagesC) in enumerate(test_loader):\n",
    "    # imagesA = imagesA.cuda()\n",
    "    # imagesB = imagesB.cuda()\n",
    "    # imagesC = imagesC.cuda()\n",
    "\n",
    "    begin_time = time.time()\n",
    "    _, _, _, _, result_mcs = model(imagesA, imagesB, imagesC)\n",
    "    outPRED_mcs = torch.cat((outPRED_mcs, result_mcs.data), 0)\n",
    "    batch_time = time.time() - begin_time\n",
    "    bar.suffix = '{} / {} | Time: {batch_time:.4f}'.format(epochID + 1, len(test_loader),\n",
    "                                                           batch_time=batch_time * (iters_per_epoch - epochID) / 60)\n",
    "    bar.next()\n",
    "bar.finish()\n",
    "\n",
    "# save result into excel:\n",
    "save_file_name = os.path.join('/opt/notebooks/{}.csv'.format(quality))\n",
    "save_output(label_test_file, outPRED_mcs, args, save_file=save_file_name)\n",
    "\n",
    "hdf5_path = '/opt/notebooks/{}.hdf5'.format(quality)\n",
    "df = pd.read_csv('/opt/notebooks/{}.csv'.format(quality),index_col=0)\n",
    "images_dir = '/opt/notebooks/{}'.format(proc_path)  # 替换为实际的图像目录路径\n",
    "df['prediction'] = df[['Good','Usable','Reject']].idxmax(axis=1)\n",
    "df = df[df['prediction'] != 'Reject']\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 创建一个HDF5文件\n",
    "with h5py.File(hdf5_path, 'w') as hdf:\n",
    "    # 创建数据集来存储图像名称\n",
    "    image_names_ds = hdf.create_dataset('image_names', shape=(len(df),), dtype=h5py.string_dtype())\n",
    "    \n",
    "    # 创建一个组来存储图像\n",
    "    img_group = hdf.create_group('images')\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        img_name = row['image_name']  # 使用实际的列名\n",
    "        \n",
    "        # 读取图像\n",
    "        img_path = os.path.join(images_dir, img_name)\n",
    "        img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
    "        \n",
    "        if img is not None:\n",
    "            # 将图像数据转换为适合存储的格式\n",
    "            img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            img_data = np.array(img)\n",
    "            \n",
    "            # 存储图像数据\n",
    "            img_dataset = img_group.create_dataset(img_name, data=img_data, compression=\"gzip\", compression_opts=9)\n",
    "            \n",
    "            # 存储图像名称\n",
    "            image_names_ds[i] = img_name\n",
    "        else:\n",
    "            print(f\"Error loading image {img_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 881/881 [02:06<00:00,  6.98it/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "dx upload /opt/notebooks/left10p.hdf5 \n",
    "dx upload /opt/notebooks/left10p.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
